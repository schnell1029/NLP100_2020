{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1章: 準備運動\n",
    "スライスは[開始位置:終了位置:移動幅]を指定して文字列を抽出する."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. 文字列の逆順\n",
    ">文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "str1 = 'stressed'\n",
    "ans = str1[::-1]\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 「パタトクカシーー」\n",
    ">「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー\n"
     ]
    }
   ],
   "source": [
    "str1 = 'パタトクカシーー'\n",
    "ans = str1[::2]\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    ">「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "str1 = 'パトカー'\n",
    "str2 = 'タクシー'\n",
    "ans = ''.join([i + j for i, j in zip(str1, str2)])\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 円周率\n",
    ">“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "str1 = 'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'\n",
    "str1 = re.sub('[,\\.]', '', str1)\n",
    "splits = str1.split()\n",
    "ans = [len(i) for i in splits]\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 元素記号\n",
    ">“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭の2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10, 'Na': 11, 'Mi': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20}\n"
     ]
    }
   ],
   "source": [
    "str1 = 'Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.'\n",
    "splits = str1.split()\n",
    "one_char = [1, 5, 6, 7, 8, 9, 15, 16, 19]\n",
    "ans = {}\n",
    "for i, word in enumerate(splits):\n",
    "    if i + 1 in one_char:\n",
    "        ans[word[:1]] = i + 1\n",
    "    else:\n",
    "        ans[word[:2]] = i + 1\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. n-gram\n",
    ">与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(n, lst):\n",
    "    return list(zip(*[lst[i:] for i in range(n)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "単語bi-gram:  [('I', 'am'), ('am', 'an'), ('an', 'NLPer')]\n",
      "文字bi-gram:  [('I', ' '), (' ', 'a'), ('a', 'm'), ('m', ' '), (' ', 'a'), ('a', 'n'), ('n', ' '), (' ', 'N'), ('N', 'L'), ('L', 'P'), ('P', 'e'), ('e', 'r')]\n"
     ]
    }
   ],
   "source": [
    "str1 = 'I am an NLPer'\n",
    "words_bi_gram = ngram(2, str1.split())\n",
    "chars_bi_gram = ngram(2, str1)\n",
    "\n",
    "print('単語bi-gram: ', words_bi_gram)\n",
    "print('文字bi-gram: ', chars_bi_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 集合\n",
    ">“paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = 'paraparaparadise'\n",
    "str2 = 'paragraph'\n",
    "\n",
    "X = set(ngram(2, str1))\n",
    "Y = set(ngram(2, str2))\n",
    "\n",
    "union = X | Y\n",
    "intersection = X & Y\n",
    "difference = X - Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  {('a', 'p'), ('d', 'i'), ('a', 'r'), ('s', 'e'), ('p', 'a'), ('r', 'a'), ('i', 's'), ('a', 'd')}\n",
      "Y:  {('a', 'p'), ('a', 'g'), ('a', 'r'), ('p', 'h'), ('p', 'a'), ('r', 'a'), ('g', 'r')}\n",
      "和集合:  {('a', 'p'), ('g', 'r'), ('a', 'g'), ('d', 'i'), ('a', 'r'), ('s', 'e'), ('p', 'h'), ('p', 'a'), ('r', 'a'), ('i', 's'), ('a', 'd')}\n",
      "積集合:  {('a', 'p'), ('p', 'a'), ('a', 'r'), ('r', 'a')}\n",
      "差集合:  {('i', 's'), ('s', 'e'), ('a', 'd'), ('d', 'i')}\n",
      "Xにseが含まれるか: True\n",
      "Yにseが含まれるか: False\n"
     ]
    }
   ],
   "source": [
    "print('X: ', X)\n",
    "print('Y: ', Y)\n",
    "print('和集合: ', union)\n",
    "print('積集合: ', intersection)\n",
    "print('差集合: ', difference)\n",
    "print('Xにseが含まれるか:', {('s', 'e')} <= X)\n",
    "print('Yにseが含まれるか:', {('s', 'e')} <= Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. テンプレートによる文生成\n",
    ">引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(x,y,z):\n",
    "    return str(x) + '時の' + y + 'は' + str(z)\n",
    "# def generate_sentence2(x, y, z):\n",
    "#     print(f'{x}時のとき{y}は{z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "ans = generate_sentence(12, '気温', 22.4)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08.暗号文\n",
    ">与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    ">- 英小文字ならば(219 - 文字コード)の文字に置換\n",
    ">- その他の文字はそのまま出力\n",
    ">\n",
    ">この関数を用い，英語のメッセージを暗号化・復号化せよ．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cipher(string):\n",
    "    res = [chr(219-ord(s)) if s.islower() else s for s in string]\n",
    "    return ''.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "暗号化: Qfvvm Eorazyvgs zmw Dfpv lu Ewrmyfits ivxvrev Clerw-19 ezxxrmv\n",
      "複号化: Queen Elizabeth and Duke of Edinburgh receive Covid-19 vaccine\n"
     ]
    }
   ],
   "source": [
    "string = 'Queen Elizabeth and Duke of Edinburgh receive Covid-19 vaccine'\n",
    "message = cipher(string)\n",
    "print('暗号化:', message)\n",
    "message = cipher(message)\n",
    "print('複号化:', message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09.TypoglycemiaPermalink\n",
    ">スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def shuffle(words):\n",
    "    result = []\n",
    "    for word in words.split():\n",
    "        if len(word) > 4:\n",
    "            word = word[:1] + ''.join(random.sample(word[1:-1], len(word) - 2)) + word[-1:]\n",
    "        result.append(word)\n",
    "    \n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cdonul’t bvleiee that I could aluclaty usnarndetd what I was rdienag : the phnmoaenel poewr of the human mind .\n"
     ]
    }
   ],
   "source": [
    "words = 'I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .'\n",
    "ans = shuffle(words)\n",
    "\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
